{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "EmDigIt Feature Tagging and Categorization\n",
        "This Jupyter Notebook is designed to process, analyze, and categorize historical itinerary data from the EmDigIt project. It streamlines the extraction of key locations, descriptors, and economic or geographical features mentioned in historical texts by applying regex-based tagging, feature extraction, and classification techniques. The pipeline consists of three main components:\n",
        "\n",
        "Data Preparation & Cleaning: The notebook begins by importing the dataset from a shared Google Drive location and performing initial preprocessing, including removing redundant content, handling missing values, and ensuring consistent formatting.\n",
        "\n",
        "Feature and Descriptor Extraction: A regex-based pattern matching system is used to identify and tag important features such as castles, rivers, towns, and markets, as well as descriptors like \"famous,\" \"beautiful,\" and \"rich\" to provide deeper insights into historical narratives. This step leverages optimized regex operations and vectorized Pandas functions for efficiency.\n",
        "\n",
        "Categorization & Data Export: The processed data is classified into economic and geographical categories based on predefined rules, allowing researchers to analyze patterns of trade, movement, and settlement over time. Finally, the cleaned and categorized dataset is exported for further study or visualization.\n",
        "\n",
        "By implementing optimized, scalable methods for text parsing and feature tagging, this notebook enhances the efficiency and accuracy of historical data analysis while ensuring maintainability for future extensions."
      ],
      "metadata": {
        "id": "utTOQzVL6gxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Data Import"
      ],
      "metadata": {
        "id": "0XeMUhM85apO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq1beqhT5QgT"
      },
      "outputs": [],
      "source": [
        "# Install and Import Required Packages\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure compatibility with numpy version\n",
        "!pip uninstall -y numpy\n",
        "%pip install \"numpy<2\"\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load Data (Corrected Path)\n",
        "df = pd.read_csv(\"/content/drive/Shareddrives/EmDigIt/Processing/full_test_df.csv\")\n",
        "\n",
        "# Function to Remove Substring\n",
        "def remove_substring(substring, string):\n",
        "    return re.compile(re.escape(substring), re.IGNORECASE).sub('', string)\n",
        "\n",
        "# Remove Content from Cleaned Column\n",
        "df['content_no_location'] = df.apply(\n",
        "    lambda row: remove_substring(str(row['cleaned']).strip(), str(row['content']).strip())\n",
        "    if pd.notnull(row['content']) and pd.notnull(row['cleaned']) else row['content'], axis=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature and Descriptor Tagging\n"
      ],
      "metadata": {
        "id": "kBEZBkuE59uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature and Descriptor Dictionaries\n",
        "features = {\n",
        "    \"Castle\": r\"castell\", \"Toll\": r\"si paga|si mostra|dogana| registr\",\n",
        "    \"River\": r\" fium|canale|si passa il\", \"Lake\": r\" lago | lagho \",\n",
        "    \"Forest\": r\" bosc|selva \", \"Inn\": r\"osteria|venta| host\",\n",
        "    \"University\": r\" studio|, universit\", \"Estate\": r\" villa | uilla | uillet| villet\",\n",
        "    \"Town\": r\"villag|uillag\", \"City\": r\"citt\", \"Cathedral\": r\"duomo\",\n",
        "    \"Church\": r\" chies\", \"Convent/Monastery\": r\"convento|monasteri\",\n",
        "    \"Village\": r\" borgo| borge|,borg\", \"Hamlet\": r\" borgh\",\n",
        "    \"Mountain\": r\" mont|montagna\", \"Region\": r\" terra | campagna\",\n",
        "    \"Residence\": r\"risiede|abitava| corte | palaz| Ã¨ del\", \"Fort\": r\"fortez| rocca\",\n",
        "    \"Baths\": r\"bagn\", \"Market\": r\"mercat| fiere\"\n",
        "}\n",
        "\n",
        "descriptors = {\n",
        "    \"Famous\": r\" famos*|celebr|notab|notev\", \"Beautiful\": r\" beliss| bel | bella\",\n",
        "    \"Rich\": r\" ricchiss*\", \"Mercantile\": r\"mercantile\", \"Capital\": r\"metropoli| capo de\",\n",
        "    \"Expedient\": r\"espedient*\", \"Good\": r\"bona|buon|ottim\", \"Bad\": r\"cattiv|mal\",\n",
        "    \"Large\": r\"gross*\", \"By Boat\": r\"per barca|in barca|sopra barca|imbarca\",\n",
        "    \"By Ascending\": r\"si ascende*|salire*\", \"By Bridge\": r\"sopra il ponte\",\n",
        "    \"Border\": r\"primo luogo|che divide|frontera|comincia l|finisce i|confin\",\n",
        "    \"Holy\": r\" santo| santa| santi\", \"High\": r\" alta \", \"Abundant\": r\"copios*\",\n",
        "    \"Powerful\": r\"potentiss*\", \"By Sedan\": r\"si fanno portare\",\n",
        "    \"By Sea\": r\"per mare|galere|galeazza|in mare\", \"Devout\": r\"divot*\", \"Strong\": r\"fortis\"\n",
        "}\n",
        "\n",
        "# Function to Match Features and Descriptors\n",
        "def match_patterns(content, patterns):\n",
        "    return '|'.join(sorted([feature for feature, regex in patterns.items() if re.search(regex, content, re.IGNORECASE)])) or None\n",
        "\n",
        "# Apply Feature and Descriptor Matching\n",
        "df['features'] = df['content_no_location'].apply(lambda x: match_patterns(x, features))\n",
        "df['descriptors'] = df['content_no_location'].apply(lambda x: match_patterns(x, descriptors))\n"
      ],
      "metadata": {
        "id": "TL_C24g_57vA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorization and Export"
      ],
      "metadata": {
        "id": "JMt02ngH5_4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Category Dictionary for Classification\n",
        "categories = {\n",
        "    \"Economic\": {\n",
        "        \"content_no_location\": r\"si fabrican|si serv|industria|popoli|vettova|bottegh|frutt\",\n",
        "        \"features\": r\"Toll|Market|Inn|Baths\",\n",
        "        \"descriptors\": r\"Rich|Mercantile\"\n",
        "    },\n",
        "    \"Crossing\": {\n",
        "        \"content_no_location\": r\"ove passa|si passa|passaret|passate|imbarca|salire|per mare|entra|intra|barc\",\n",
        "        \"features\": r\"Mountain|River\",\n",
        "        \"descriptors\": r\"By Boat|By Ascending|By Sedan|By Sea|By Bridge\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Export Processed Data (Corrected Path)\n",
        "df.to_csv('/content/drive/Shareddrives/EmDigIt/Processing/feature_tagged.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Ril9MfA06Ah5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}